{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***MNIST Example***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please make sure that you have the following libraries, otherwise you shall install them.\n",
    "# just uncomment the pip command down below and run this cell\n",
    "# %pip install numpy matplotlib idx2numpy os plotly\n",
    "# pip install -U kaleido   # in cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join, isdir\n",
    "import plotly.graph_objects as go\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = idx2numpy.convert_from_file(\n",
    "    './dataset/train-images-idx3-ubyte').reshape(60000, 784)\n",
    "X_cv, X_train = X_train[0 : 10000, :], X_train[10000 ::, :]\n",
    "X_test = idx2numpy.convert_from_file(\n",
    "    './dataset/t10k-images-idx3-ubyte').reshape(10000, 784)\n",
    "y_train = idx2numpy.convert_from_file('./dataset/train-labels-idx1-ubyte')\n",
    "y_cv, y_train = y_train[0 : 10000], y_train[10000 ::]\n",
    "y_test = idx2numpy.convert_from_file('./dataset/t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_cv.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_cv.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X_train.shape\n",
    "\n",
    "fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
    "fig.tight_layout(pad=0.1)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "\n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X_train[random_index].reshape((28, 28))\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='PuBuGn')\n",
    "\n",
    "    # Display the label above the image\n",
    "    ax.set_title(y_train[random_index])\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z): return np.maximum(0, Z)\n",
    "\n",
    "def sigmoid(Z): return 1.0 / (1.0 + np.exp(-Z))\n",
    "\n",
    "def softmax(Z):\n",
    "    exponentias = np.exp(Z - np.max(Z, axis=1).reshape(-1, 1))\n",
    "    return exponentias / np.sum(exponentias, axis=1).reshape(-1, 1)\n",
    "\n",
    "def relu_derevative(Z): return Z > 0\n",
    "\n",
    "def sigmoid_derevative(sig): return sig * (1.0 - sig)\n",
    "\n",
    "def softmax_grad(soft):\n",
    "    s = soft.reshape(-1, 1)\n",
    "    return np.diagflat(s) - np.dot(s, s.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, neurons, activation, activation_drev):\n",
    "        self.neurons = neurons\n",
    "        self.activation = activation\n",
    "        self.activation_drev = activation_drev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, X_train, X_cv, X_test, y_train, y_cv, y_test, **layers):\n",
    "        self.m = X_train.shape[0]\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "        self.X_train_norm = X_train / 255\n",
    "        self.X_test_norm = X_test / 255\n",
    "        self.X_cv_norm = X_cv / 255\n",
    "\n",
    "        self.y_train = np.array([self.convert2_OneHotEncodeing(y) for y in y_train])\n",
    "        self.y_cv = np.array([self.convert2_OneHotEncodeing(y) for y in y_cv])\n",
    "        self.y_test = np.array([self.convert2_OneHotEncodeing(y) for y in y_test])\n",
    "\n",
    "        self.layers = list(layers.items())\n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.V_dw = []\n",
    "        self.V_db = []\n",
    "        self.S_dw = []\n",
    "        self.S_db = []\n",
    "\n",
    "        self.j_train = np.array([])\n",
    "        self.accuracy = np.array([])\n",
    "        \n",
    "        for index, layer in enumerate(self.layers):\n",
    "            if index == 0:\n",
    "                self.Weights.append(np.random.rand(\n",
    "                    self.X_train_norm.shape[1], layer[1].neurons) * 0.1 - 0.05)\n",
    "            else:\n",
    "                self.Weights.append(np.random.rand(\n",
    "                    self.layers[index - 1][1].neurons, layer[1].neurons) * 0.1 - 0.05)\n",
    "            self.Biases.append(np.zeros(shape=(1, layer[1].neurons)))\n",
    "\n",
    "            self.V_dw.append(np.zeros_like(self.Weights[index]))\n",
    "            self.V_db.append(np.zeros_like(self.Biases[index]))\n",
    "            self.S_dw.append(np.zeros_like(self.Weights[index]))\n",
    "            self.S_db.append(np.zeros_like(self.Biases[index]))\n",
    "\n",
    "    def convert2_OneHotEncodeing(self, index):\n",
    "        e = np.zeros((10))\n",
    "        e[index] = 1.0\n",
    "        return e\n",
    "\n",
    "    def data_normalize(self, X):\n",
    "        X_norm = [0 for i in range(X.shape[1])]\n",
    "        for index in range(X.shape[1]):\n",
    "            avg = np.average(X[:, index])\n",
    "            std = np.std(X[:, index])\n",
    "            if std != 0:\n",
    "                X_norm[index] = (X[:, index] - avg) / std\n",
    "            else:\n",
    "                X_norm[index] = X[:, index]\n",
    "        return np.array(X_norm).T\n",
    "\n",
    "    def parameters(self):\n",
    "        n_weights = 0\n",
    "        for W, B in zip(self.Weights, self.Biases):\n",
    "            n_weights += np.size(W) + np.size(B)\n",
    "        return n_weights\n",
    "\n",
    "    def dense(self, A_in, W, B, activation):\n",
    "        Z = np.matmul(A_in, W) + B\n",
    "        self.Z.append(Z)\n",
    "        A_out = activation(Z)\n",
    "        return A_out\n",
    "\n",
    "    def forwardPropagation(self, X):\n",
    "        self.A = [X]\n",
    "        self.Z = []\n",
    "        for index, layer in enumerate(self.layers):\n",
    "            self.A.append(self.dense(\n",
    "                self.A[index], self.Weights[index], self.Biases[index], layer[1].activation))\n",
    "        self.y_predict = self.A[-1]\n",
    "\n",
    "    def backwardPropagation(self, y_batch, learning_rate, lambda_, beta1, beta2, t):\n",
    "        delta = self.cross_entropy_grad(y_batch) / self.m\n",
    "        dw = np.matmul(self.A[-2].T, delta)\n",
    "        db = np.sum(delta, axis=0).reshape(1, -1)\n",
    "        for index in reversed(np.arange(len(self.layers))):\n",
    "            self.V_dw[index], self.V_db[index] = beta1 * self.V_dw[index] + (1.0 - beta1) * dw, beta1 * self.V_db[index] + (1.0 - beta1) * db\n",
    "            self.S_dw[index], self.S_db[index] = beta2 * self.S_dw[index] + (1.0 - beta2) * (dw ** 2), beta2 * self.S_db[index] + (1.0 - beta2) * (db ** 2)\n",
    "            \n",
    "            V_dw_correct, V_db_correct = self.V_dw[index] / (1.0 - beta1 ** (t + 1)), self.V_db[index] / (1.0 - beta1 ** (t + 1))\n",
    "            S_dw_correct, S_db_correct = self.S_dw[index] / (1.0 - beta2 ** (t + 1)), self.S_db[index] / (1.0 - beta2 ** (t + 1))\n",
    "            \n",
    "            adam_dw = learning_rate * V_dw_correct / (np.sqrt(S_dw_correct) + self.epsilon)\n",
    "            adam_db = learning_rate * V_db_correct / (np.sqrt(S_db_correct) + self.epsilon)\n",
    "            \n",
    "            self.Weights[index] = self.Weights[index] * (1 - learning_rate * lambda_ / self.m) - adam_dw\n",
    "            self.Biases[index] -= adam_db\n",
    "\n",
    "            if index == 0: break\n",
    "            delta = np.matmul(\n",
    "                delta, self.Weights[index].T) * self.layers[index - 1][1].activation_drev(self.Z[index - 1])\n",
    "            dw = np.matmul(self.A[index - 1].T, delta)\n",
    "            db = np.sum(delta, axis=0).reshape(1, -1)\n",
    "\n",
    "    def fit(self, epochs=100, learning_rate=0.02, beta1=0.9, beta2=0.999, lambda_=0.0, mini_batch=128, learning_rate_decay=0.1):\n",
    "        num_batches = int(self.m / mini_batch)\n",
    "        tic = time()\n",
    "        \n",
    "        self.forwardPropagation(X=self.X_train_norm)\n",
    "        self.j_train = np.append(self.j_train, self.cross_entropy(self.y_train, lambda_))\n",
    "        acc = 100.0 * self.getAccuracy(y=self.y_train)\n",
    "        self.accuracy = np.append(self.accuracy, acc)\n",
    "        \n",
    "        print(f'epoch: {0}')\n",
    "        print(f'training set prediction accuracy {acc}')\n",
    "\n",
    "        for epoch in np.arange(1, epochs + 1):\n",
    "            start, end = 0, 0\n",
    "            \n",
    "            for batch in np.arange(num_batches):\n",
    "                end = (batch + 1) * mini_batch\n",
    "                X_batch, y_batch = self.X_train_norm[start:end, :], self.y_train[start:end, :]\n",
    "                start = end\n",
    "                self.forwardPropagation(X_batch)\n",
    "                self.backwardPropagation(y_batch, learning_rate, lambda_, beta1, beta2, batch)\n",
    "\n",
    "            X_batch, y_batch = self.X_train_norm[end::, :], self.y_train[end::, :]\n",
    "            self.forwardPropagation(X_batch)\n",
    "            self.backwardPropagation(y_batch, learning_rate, lambda_, beta1, beta2, batch)\n",
    "\n",
    "            self.forwardPropagation(X=self.X_train_norm)\n",
    "            self.j_train = np.append(self.j_train, self.cross_entropy(self.y_train, lambda_))\n",
    "            acc = 100.0 * self.getAccuracy(y=self.y_train)\n",
    "            self.accuracy = np.append(self.accuracy, acc)\n",
    "            \n",
    "            learning_rate /= (1.0 + learning_rate_decay * (epoch - 1))\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'epoch: {epoch}')\n",
    "                print(f'training set prediction accuracy {acc}')\n",
    "                if np.abs(self.j_train[epoch] - self.j_train[epoch - 1]) <= self.epsilon:\n",
    "                    break\n",
    "        \n",
    "        toc = time()\n",
    "        self.executed_time = toc - tic\n",
    "        self.testModel()\n",
    "\n",
    "    def getAccuracy(self, y):\n",
    "        return np.sum(\n",
    "            np.argmax(self.y_predict, axis=1) == np.argmax(y, axis=1)\n",
    "            ) / self.y_predict.shape[0]\n",
    "\n",
    "    def testModel(self):\n",
    "        x = np.arange(len(self.j_train))\n",
    "        self.j_train_fig = go.Figure(go.Scatter(x=x, y=self.j_train)).update_layout( \n",
    "            title='Cost function of training examples', \n",
    "            xaxis_title='epochs', \n",
    "            yaxis_title='J_train', \n",
    "            template='plotly_dark')\n",
    "\n",
    "        self.j_train_fig.show()\n",
    "        self.accuracy_fig = go.Figure(go.Scatter(x=x, y=self.accuracy)).update_layout( \n",
    "            title='Accuracy of training examples', \n",
    "            xaxis_title='epochs', \n",
    "            yaxis_title='accuracy', \n",
    "            template='plotly_dark')\n",
    "\n",
    "        self.accuracy_fig.show()\n",
    "\n",
    "    def saveModel(self, index, learning_rate=0.02, beta1=0.9, beta2=0.999, lambda_=0.0, mini_batch=128, learning_rate_decay=0.1):\n",
    "        if not isdir(f'./models/model_{index}/'):\n",
    "            mkdir(f'./models/model_{index}/')\n",
    "\n",
    "        # saving the plots we have done through the cost functions plots\n",
    "        self.j_train_fig.write_image(f'./models/model_{index}/j_train_graph.png')\n",
    "        self.accuracy_fig.write_image(f'./models/model_{index}/accuracy_graph.png')\n",
    "\n",
    "        # saving parameters\n",
    "        for i, (w, b) in enumerate(zip(self.Weights, self.Biases)):\n",
    "            np.savetxt(f'./models/model_{index}/W_{i}.txt', w, fmt='%1.9f')\n",
    "            np.savetxt(f'./models/model_{index}/B_{i}.txt', b, fmt='%1.9f')\n",
    "        \n",
    "        # saving the cost functions arrays\n",
    "        np.savetxt(f'./models/model_{index}/J-train.txt', self.j_train, fmt='%1.9f')\n",
    "        np.savetxt(f'./models/model_{index}/accuracy.txt', self.accuracy, fmt='%1.9f')\n",
    "        \n",
    "        # add model's summary \n",
    "        with open(f'./models/model_{index}/model_summary.md', \"w\") as f:\n",
    "            f.write(f'# ***Model {index}***\\n\\n')\n",
    "            f.write(f'Here is the summary of a trained model for the MNIST dataset.\\n\\n')\n",
    "            f.write(f'## **1. Model Design**\\n')\n",
    "            f.write(f'## This model is consisted of *{len(self.layers)}* layers\\n\\n')\n",
    "\n",
    "            for i in np.arange(len(self.layers)):\n",
    "                f.write(f'Layer {i + 1}:\\n')\n",
    "                f.write(f'Layer {i + 1} is consisted of *{self.Weights[i].shape[1]}* neurons.\\n\\n')\n",
    "                f.write(f'so the shape of its *Weights and Biases* are:\\n\\n')\n",
    "                f.write(f'- Weights = {self.Weights[i].shape}\\n\\n')\n",
    "                f.write(f'- Biases = {self.Biases[i].shape}\\n\\n')\n",
    "\n",
    "            f.write(f'The total parameters of this model = {self.parameters()}\\n')\n",
    "\n",
    "            f.write(f'## **3. Model\\'s Hyperparametes**\\n')\n",
    "\n",
    "            f.write(\n",
    "                f'''- ### Model\\'s hyperparameters are:\\n\n",
    "                Batch size (mini batch): {mini_batch} training examples\\n\n",
    "                Learning rate (alpha): {learning_rate}\\n\n",
    "                Learning rate decay: {learning_rate_decay}\\n\n",
    "                Regularization term -L2 regularization- (lambda): {lambda_}\\n\n",
    "                Gradient descent with momentum hyperparameter (beta 1): {beta1}\\n\n",
    "                RMSprop hyperparameter (beta 2): {beta2}\\n\\n'''\n",
    "            )\n",
    "            f.write(f'## **3. Model\\'s Accuracy**\\n')\n",
    "\n",
    "            self.forwardPropagation(self.X_train_norm)\n",
    "            train_loss = self.cross_entropy(self.y_train, lambda_)\n",
    "            f.write(f'- ### Model\\'s accuracy of the training examples:\\\n",
    "                {self.getAccuracy(self.y_train) * 100}\\n\\n')\n",
    "            \n",
    "            f.write(f'![Accuracy of training examples](./accuracy_graph.png)\\n\\n')\n",
    "\n",
    "            self.forwardPropagation(self.X_cv_norm)\n",
    "            cv_loss = self.cross_entropy(self.y_cv, lambda_)\n",
    "            f.write(f'- ### Model\\'s accuracy of the cross validating examples:\\\n",
    "                {self.getAccuracy(self.y_cv) * 100}\\n\\n')\n",
    "            \n",
    "            self.forwardPropagation(self.X_test_norm)\n",
    "            test_loss = self.cross_entropy(self.y_test, lambda_)\n",
    "            f.write(f'- ### Model\\'s accuracy of the testing examples:\\\n",
    "                {self.getAccuracy(self.y_test) * 100}\\n\\n')\n",
    "\n",
    "            f.write(f'## **4. Model\\'s Losses**\\n')\n",
    "\n",
    "            f.write(f'- ### Model\\'s losses of the training examples: {train_loss}\\n\\n')\n",
    "\n",
    "            f.write(f'![Cost function of training examples](./j_train_graph.png)\\n\\n')\n",
    "\n",
    "            f.write(f'- ### Model\\'s losses of the cross validating examples: {cv_loss}\\n\\n')\n",
    "\n",
    "            f.write(f'- ### Model\\'s losses of the testing examples: {test_loss}\\n\\n')\n",
    "\n",
    "            f.write(f'## **5. Model\\'s Executed time**\\n')\n",
    "\n",
    "            f.write(f'- ### The executed time: {int(self.executed_time / 60)} minutes,, \\\n",
    "            {int(self.executed_time % 60)} seconds ,, \\\n",
    "                {((self.executed_time - int(self.executed_time)) * 1000):.2f} milli seconds, along {len(self.accuracy) - 1} epochs\\n\\n')\n",
    "\n",
    "    def loadModel(self, index):\n",
    "        path = f'./models/model_{index}/'\n",
    "        files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "        self.Biases, self.Weights = [], []\n",
    "\n",
    "        for file in files:\n",
    "            for i in np.arange(len(files)):\n",
    "                if file == f'B_{i}.txt':\n",
    "                    self.Biases.append(np.loadtxt(join(path, f'B_{i}.txt')).reshape(1, -1))\n",
    "                    break\n",
    "                elif file == f'W_{i}.txt':\n",
    "                    self.Weights.append(np.loadtxt(join(path, f'W_{i}.txt')))\n",
    "                    break\n",
    "\n",
    "        if len(self.Biases) != len(self.Weights) != len(self.layers):\n",
    "            print('failed to load the model due to an error:')\n",
    "            print('len(self.Biases) not equal len(self.Weights)')\n",
    "            print('please make sure you are loading the right model')\n",
    "            self.Biases, self.Weights = [], []\n",
    "            return\n",
    "\n",
    "        if isfile(join(path, 'J-train.txt')): \n",
    "            self.j_train = np.loadtxt(join(path, 'J-train.txt'))\n",
    "        else : print('failed to load J-train file')\n",
    "\n",
    "        if isfile(join(path, 'accuracy.txt')): \n",
    "            self.j_train = np.loadtxt(join(path, 'accuracy.txt'))\n",
    "        else : print('failed to load accuracy file')\n",
    "\n",
    "        for w, b in zip(self.Weights, self.Biases):\n",
    "            print(f'Weights: {w.shape}')\n",
    "            print(f'Biases: {b.shape}')\n",
    "\n",
    "    def cross_entropy(self, y, lambda_):\n",
    "        regularization_term = 0\n",
    "        \n",
    "        for w in self.Weights:\n",
    "            regularization_term += lambda_ / 2 * np.mean(w ** 2)\n",
    "\n",
    "        y_pred_clipped = np.clip(self.y_predict, self.epsilon, 1 - self.epsilon)\n",
    "        return np.mean(-y * np.log(y_pred_clipped)) + regularization_term\n",
    "\n",
    "    def cross_entropy_grad(self, y): return self.y_predict - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    X_train=X_train,\n",
    "    X_cv=X_cv,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_cv=y_cv,\n",
    "    y_test=y_test,\n",
    "    layer1=Layer(neurons=25, activation=relu, activation_drev=relu_derevative),\n",
    "    layer2=Layer(neurons=15, activation=relu, activation_drev=relu_derevative),\n",
    "    layer3=Layer(neurons=10, activation=softmax, activation_drev=softmax_grad)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "ALPHA = 0.03\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "LAMBDA = 0.0\n",
    "LEARNING_RATE_DECAY = 0.0005\n",
    "NUM_EPOCHS = 100\n",
    "MINI_BATCH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(NUM_EPOCHS, ALPHA, BETA_1, BETA_2, LAMBDA, MINI_BATCH, LEARNING_RATE_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forwardPropagation(model.X_train_norm)\n",
    "print(f'training set prediction accuracy {100 * model.getAccuracy(y=model.y_train)}')\n",
    "\n",
    "model.forwardPropagation(model.X_cv_norm)\n",
    "print(f'testing set prediction accuracy {100 * model.getAccuracy(y=model.y_cv)}')\n",
    "\n",
    "model.forwardPropagation(model.X_test_norm)\n",
    "print(f'testing set prediction accuracy {100 * model.getAccuracy(y=model.y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forwardPropagation(model.X_test_norm)\n",
    "\n",
    "m, n = X_test.shape\n",
    "\n",
    "fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
    "fig.tight_layout(pad=0.1,rect=[0, 0.03, 1, 0.92]) #[left, bottom, right, top]\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X_test[random_index].reshape((28,28))\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='PuBuGn')\n",
    "    \n",
    "    # Predict using the Neural Network\n",
    "    yhat = np.argmax(model.y_predict[random_index])\n",
    "\n",
    "    # Display the label above the image\n",
    "    ax.set_title(f\"{y_test[random_index]},{yhat}\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "fig.suptitle(\"Label, yhat\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.saveModel(index=2, learning_rate=ALPHA, beta1=BETA_1, beta2=BETA_2, lambda_=LAMBDA, mini_batch=MINI_BATCH, learning_rate_decay=LEARNING_RATE_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f9de6002feec04b404f0b7f8f6587025d4443351c01b275e2f110528afd180c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
